{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de5bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Data preparation script for essay dataset - PLMs and CBE-PLMs only.\n",
    "\n",
    "This script processes the raw essay data and creates the required CSV files\n",
    "for PLMs (standard) and CBE-PLMs (joint) experiments.\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "WORK_DIR = Path('.').absolute()\n",
    "DATA_DIR = WORK_DIR / \"raw\"\n",
    "OUTPUT_DIR = WORK_DIR / \"cleaned\"\n",
    "\n",
    "# Input file\n",
    "SRC = DATA_DIR / \"QA_train_annotated.csv\"\n",
    "\n",
    "# Output files (only manual variants needed)\n",
    "OUT_TRAIN_MAN = OUTPUT_DIR / \"train_manual.csv\"\n",
    "OUT_DEV_MAN = OUTPUT_DIR / \"dev_manual.csv\"\n",
    "OUT_TEST_MAN = OUTPUT_DIR / \"test_manual.csv\"\n",
    "\n",
    "# Concept columns\n",
    "CONCEPT_COLS = [\"FC\", \"CC\", \"TU\", \"CP\", \"R\", \"DU\", \"EE\", \"FR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0017662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_concept(v):\n",
    "    \"\"\"Map numerical concept scores to categorical labels.\"\"\"\n",
    "    try:\n",
    "        v = int(v)\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "    if v == 3:\n",
    "        return \"Positive\"\n",
    "    if v == 2:\n",
    "        return \"unknown\"\n",
    "    return \"Negative\"\n",
    "\n",
    "\n",
    "def to_text(row):\n",
    "    \"\"\"Convert question and answer to text format.\"\"\"\n",
    "    q = str(row.get(\"question\", \"\")).strip()\n",
    "    a = str(row.get(\"student_answer\", \"\")).strip()\n",
    "    if q and a:\n",
    "        return f\"Q: {q}\\nA: {a}\"\n",
    "    return a or q\n",
    "\n",
    "\n",
    "def to_label_binary(v):\n",
    "    \"\"\"Convert score_avg to binary label (threshold: 3.5).\"\"\"\n",
    "    try:\n",
    "        s = float(v)\n",
    "    except Exception:\n",
    "        return 0\n",
    "    return 1 if s >= 3.5 else 0\n",
    "\n",
    "\n",
    "def load_and_transform():\n",
    "    \"\"\"Load and transform the raw data.\"\"\"\n",
    "    print(f\"Loading data from: {SRC}\")\n",
    "    df = pd.read_csv(SRC)\n",
    "    \n",
    "    out = pd.DataFrame()\n",
    "    out[\"text\"] = df.apply(to_text, axis=1)\n",
    "    out[\"label\"] = df[\"score_avg\"].apply(to_label_binary)\n",
    "    \n",
    "    # Map concept columns\n",
    "    for c in CONCEPT_COLS:\n",
    "        if c in df.columns:\n",
    "            out[c] = df[c].apply(map_concept)\n",
    "        else:\n",
    "            out[c] = \"unknown\"\n",
    "    \n",
    "    # Clean data\n",
    "    out = out.dropna(subset=[\"text\", \"label\"])\n",
    "    out = out[out[\"text\"].astype(str).str.strip() != \"\"].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Loaded {len(out)} samples after cleaning\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def stratified_split(df, seed=42):\n",
    "    \"\"\"Perform stratified split to maintain label distribution (7:2:1 ratio).\"\"\"\n",
    "    # First split: 70% train, 30% temp (dev + test)\n",
    "    train, temp = train_test_split(\n",
    "        df, test_size=0.30, stratify=df[\"label\"], random_state=seed\n",
    "    )\n",
    "    # Second split: from 30%, get 20% dev and 10% test\n",
    "    # 20% of total = 30% * (2/3), 10% of total = 30% * (1/3)\n",
    "    dev, test = train_test_split(\n",
    "        temp, test_size=1/3, stratify=temp[\"label\"], random_state=seed\n",
    "    )\n",
    "    return train.reset_index(drop=True), dev.reset_index(drop=True), test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def validate_data(df, name):\n",
    "    \"\"\"Validate data quality.\"\"\"\n",
    "    print(f\"\\n=== {name} Validation ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Label distribution: {df['label'].value_counts(normalize=True).to_dict()}\")\n",
    "    \n",
    "    # Check concept distributions\n",
    "    for col in CONCEPT_COLS:\n",
    "        dist = df[col].value_counts(normalize=True).to_dict()\n",
    "        print(f\"{col}: {dist}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = df[[\"text\", \"label\"] + CONCEPT_COLS].isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"Missing values: {missing[missing > 0].to_dict()}\")\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main data preparation function.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ESSAY DATASET PREPARATION - PLMs & CBE-PLMs ONLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Load and transform data\n",
    "    df = load_and_transform()\n",
    "    \n",
    "    # Split data\n",
    "    print(\"\\nPerforming stratified split...\")\n",
    "    train, dev, test = stratified_split(df)\n",
    "    \n",
    "    # Save manual files (only these are needed)\n",
    "    print(\"\\nSaving manual files...\")\n",
    "    train.to_csv(OUT_TRAIN_MAN, index=False)\n",
    "    dev.to_csv(OUT_DEV_MAN, index=False)\n",
    "    test.to_csv(OUT_TEST_MAN, index=False)\n",
    "    \n",
    "    print(f\"Saved to: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Validate outputs\n",
    "    validate_data(train, \"Train\")\n",
    "    validate_data(dev, \"Dev\")\n",
    "    validate_data(test, \"Test\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    def stats(name, part):\n",
    "        print(f\"{name}: n={len(part)}, label=1比例={part['label'].mean():.3f}\")\n",
    "    \n",
    "    stats(\"Train\", train)\n",
    "    stats(\"Dev\", dev)\n",
    "    stats(\"Test\", test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DATA PREPARATION COMPLETED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Files created:\")\n",
    "    print(f\"  - {OUT_TRAIN_MAN}\")\n",
    "    print(f\"  - {OUT_DEV_MAN}\")\n",
    "    print(f\"  - {OUT_TEST_MAN}\")\n",
    "    print(\"\\nReady for PLMs and CBE-PLMs experiments!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac1cb3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ESSAY DATASET PREPARATION - PLMs & CBE-PLMs ONLY\n",
      "============================================================\n",
      "Loading data from: /Users/scott/repos/CBM_NLP/dataset/essay/raw/QA_train_annotated.csv\n",
      "Loaded 2273 samples after cleaning\n",
      "\n",
      "Performing stratified split...\n",
      "\n",
      "Saving manual files...\n",
      "Saved to: /Users/scott/repos/CBM_NLP/dataset/essay/cleaned\n",
      "\n",
      "=== Train Validation ===\n",
      "Shape: (1591, 10)\n",
      "Label distribution: {1: 0.792583280955374, 0: 0.20741671904462602}\n",
      "FC: {'Positive': 0.48774355751099935, 'Negative': 0.2960402262727844, 'unknown': 0.21621621621621623}\n",
      "CC: {'Negative': 0.38843494657448147, 'Positive': 0.3846637335009428, 'unknown': 0.22690131992457574}\n",
      "TU: {'Positive': 0.5065996228786926, 'unknown': 0.2891263356379635, 'Negative': 0.2042740414833438}\n",
      "CP: {'Positive': 0.40917661847894404, 'unknown': 0.3117536140791955, 'Negative': 0.27906976744186046}\n",
      "R: {'Positive': 0.7467001885606537, 'unknown': 0.13827781269641734, 'Negative': 0.11502199874292897}\n",
      "DU: {'Positive': 0.4110622250157134, 'Negative': 0.37460716530483973, 'unknown': 0.2143306096794469}\n",
      "EE: {'Negative': 0.7743557510999372, 'unknown': 0.1565053425518542, 'Positive': 0.06913890634820867}\n",
      "FR: {'Positive': 0.8064110622250157, 'unknown': 0.15587680703959775, 'Negative': 0.03771213073538655}\n",
      "No missing values\n",
      "\n",
      "=== Dev Validation ===\n",
      "Shape: (454, 10)\n",
      "Label distribution: {1: 0.7929515418502202, 0: 0.20704845814977973}\n",
      "FC: {'Positive': 0.5110132158590308, 'Negative': 0.27973568281938327, 'unknown': 0.2092511013215859}\n",
      "CC: {'Positive': 0.40969162995594716, 'Negative': 0.3876651982378855, 'unknown': 0.2026431718061674}\n",
      "TU: {'Positive': 0.5066079295154186, 'unknown': 0.2709251101321586, 'Negative': 0.22246696035242292}\n",
      "CP: {'Positive': 0.46255506607929514, 'unknown': 0.27312775330396477, 'Negative': 0.2643171806167401}\n",
      "R: {'Positive': 0.7731277533039648, 'unknown': 0.12555066079295155, 'Negative': 0.1013215859030837}\n",
      "DU: {'Positive': 0.42951541850220265, 'Negative': 0.3744493392070485, 'unknown': 0.1960352422907489}\n",
      "EE: {'Negative': 0.8127753303964758, 'unknown': 0.12334801762114538, 'Positive': 0.06387665198237885}\n",
      "FR: {'Positive': 0.8149779735682819, 'unknown': 0.14096916299559473, 'Negative': 0.04405286343612335}\n",
      "No missing values\n",
      "\n",
      "=== Test Validation ===\n",
      "Shape: (228, 10)\n",
      "Label distribution: {1: 0.793859649122807, 0: 0.20614035087719298}\n",
      "FC: {'Positive': 0.4649122807017544, 'Negative': 0.3026315789473684, 'unknown': 0.2324561403508772}\n",
      "CC: {'Positive': 0.42105263157894735, 'Negative': 0.37719298245614036, 'unknown': 0.20175438596491227}\n",
      "TU: {'Positive': 0.5087719298245614, 'unknown': 0.27631578947368424, 'Negative': 0.2149122807017544}\n",
      "CP: {'Positive': 0.4166666666666667, 'unknown': 0.3026315789473684, 'Negative': 0.2807017543859649}\n",
      "R: {'Positive': 0.793859649122807, 'Negative': 0.11403508771929824, 'unknown': 0.09210526315789473}\n",
      "DU: {'Positive': 0.4342105263157895, 'Negative': 0.3815789473684211, 'unknown': 0.18421052631578946}\n",
      "EE: {'Negative': 0.7236842105263158, 'unknown': 0.19736842105263158, 'Positive': 0.07894736842105263}\n",
      "FR: {'Positive': 0.7631578947368421, 'unknown': 0.18859649122807018, 'Negative': 0.04824561403508772}\n",
      "No missing values\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "Train: n=1591, label=1比例=0.793\n",
      "Dev: n=454, label=1比例=0.793\n",
      "Test: n=228, label=1比例=0.794\n",
      "\n",
      "============================================================\n",
      "DATA PREPARATION COMPLETED\n",
      "============================================================\n",
      "Files created:\n",
      "  - /Users/scott/repos/CBM_NLP/dataset/essay/cleaned/train_manual.csv\n",
      "  - /Users/scott/repos/CBM_NLP/dataset/essay/cleaned/dev_manual.csv\n",
      "  - /Users/scott/repos/CBM_NLP/dataset/essay/cleaned/test_manual.csv\n",
      "\n",
      "Ready for PLMs and CBE-PLMs experiments!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c212e71",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a212541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== /Users/scott/repos/CBM_NLP/dataset/essay/cleaned/train_manual.csv ===\n",
      "列齐全\n",
      "空值计数: {'text': 0, 'label': 0, 'FC': 0, 'CC': 0, 'TU': 0, 'CP': 0, 'R': 0, 'DU': 0, 'EE': 0, 'FR': 0}\n",
      "空文本行数: 0\n",
      "label取值分布: Counter({1: 1261, 0: 330})\n",
      "FC 分布: {'Positive': 0.488, 'Negative': 0.296, 'unknown': 0.216}\n",
      "CC 分布: {'Negative': 0.388, 'Positive': 0.385, 'unknown': 0.227}\n",
      "TU 分布: {'Positive': 0.507, 'unknown': 0.289, 'Negative': 0.204}\n",
      "CP 分布: {'Positive': 0.409, 'unknown': 0.312, 'Negative': 0.279}\n",
      "R 分布: {'Positive': 0.747, 'unknown': 0.138, 'Negative': 0.115}\n",
      "DU 分布: {'Positive': 0.411, 'Negative': 0.375, 'unknown': 0.214}\n",
      "EE 分布: {'Negative': 0.774, 'unknown': 0.157, 'Positive': 0.069}\n",
      "FR 分布: {'Positive': 0.806, 'unknown': 0.156, 'Negative': 0.038}\n",
      "\n",
      "=== /Users/scott/repos/CBM_NLP/dataset/essay/cleaned/test_manual.csv ===\n",
      "列齐全\n",
      "空值计数: {'text': 0, 'label': 0, 'FC': 0, 'CC': 0, 'TU': 0, 'CP': 0, 'R': 0, 'DU': 0, 'EE': 0, 'FR': 0}\n",
      "空文本行数: 0\n",
      "label取值分布: Counter({1: 181, 0: 47})\n",
      "FC 分布: {'Positive': 0.465, 'Negative': 0.303, 'unknown': 0.232}\n",
      "CC 分布: {'Positive': 0.421, 'Negative': 0.377, 'unknown': 0.202}\n",
      "TU 分布: {'Positive': 0.509, 'unknown': 0.276, 'Negative': 0.215}\n",
      "CP 分布: {'Positive': 0.417, 'unknown': 0.303, 'Negative': 0.281}\n",
      "R 分布: {'Positive': 0.794, 'Negative': 0.114, 'unknown': 0.092}\n",
      "DU 分布: {'Positive': 0.434, 'Negative': 0.382, 'unknown': 0.184}\n",
      "EE 分布: {'Negative': 0.724, 'unknown': 0.197, 'Positive': 0.079}\n",
      "FR 分布: {'Positive': 0.763, 'unknown': 0.189, 'Negative': 0.048}\n",
      "\n",
      "=== /Users/scott/repos/CBM_NLP/dataset/essay/cleaned/dev_manual.csv ===\n",
      "列齐全\n",
      "空值计数: {'text': 0, 'label': 0, 'FC': 0, 'CC': 0, 'TU': 0, 'CP': 0, 'R': 0, 'DU': 0, 'EE': 0, 'FR': 0}\n",
      "空文本行数: 0\n",
      "label取值分布: Counter({1: 360, 0: 94})\n",
      "FC 分布: {'Positive': 0.511, 'Negative': 0.28, 'unknown': 0.209}\n",
      "CC 分布: {'Positive': 0.41, 'Negative': 0.388, 'unknown': 0.203}\n",
      "TU 分布: {'Positive': 0.507, 'unknown': 0.271, 'Negative': 0.222}\n",
      "CP 分布: {'Positive': 0.463, 'unknown': 0.273, 'Negative': 0.264}\n",
      "R 分布: {'Positive': 0.773, 'unknown': 0.126, 'Negative': 0.101}\n",
      "DU 分布: {'Positive': 0.43, 'Negative': 0.374, 'unknown': 0.196}\n",
      "EE 分布: {'Negative': 0.813, 'unknown': 0.123, 'Positive': 0.064}\n",
      "FR 分布: {'Positive': 0.815, 'unknown': 0.141, 'Negative': 0.044}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "files = glob.glob(f\"{OUTPUT_DIR}/*.csv\")\n",
    "concepts = [\"FC\",\"CC\",\"TU\",\"CP\",\"R\",\"DU\",\"EE\",\"FR\"]\n",
    "\n",
    "def check_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    need_cols = [\"text\",\"label\"] + concepts\n",
    "    missing = [c for c in need_cols if c not in df.columns]\n",
    "    print(f\"\\n=== {path} ===\")\n",
    "    if missing:\n",
    "        print(\"缺失列:\", missing)\n",
    "    else:\n",
    "        print(\"列齐全\")\n",
    "    # 空值/空文本\n",
    "    null_counts = df[need_cols].isnull().sum().to_dict()\n",
    "    print(\"空值计数:\", {k:int(v) for k,v in null_counts.items()})\n",
    "    empty_text = (df[\"text\"].astype(str).str.strip()==\"\").sum()\n",
    "    print(\"空文本行数:\", int(empty_text))\n",
    "    # 标签取值\n",
    "    print(\"label取值分布:\", Counter(df[\"label\"]))\n",
    "    # 概念合法取值\n",
    "    for c in concepts:\n",
    "        vals = set(df[c].astype(str).unique().tolist())\n",
    "        bad = vals - {\"Positive\",\"Negative\",\"unknown\"}\n",
    "        if bad:\n",
    "            print(f\"{c} 含非法取值: {bad}\")\n",
    "    # 概念分布\n",
    "    for c in concepts:\n",
    "        vc = df[c].value_counts(normalize=True).to_dict()\n",
    "        print(f\"{c} 分布:\", {k: round(v,3) for k,v in vc.items()})\n",
    "\n",
    "for f in files:\n",
    "    check_file(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
