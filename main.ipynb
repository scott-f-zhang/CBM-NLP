{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7267c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from run_cebab import get_cbm_standard, get_cbm_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fd5319-0aef-44e3-bd26-dee1c7dd49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can only run once when kernal start\n",
    "os.chdir('run_cebab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7108584a-4b6d-4e7b-a4dc-efaa36b4051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate_dt = {\n",
    "    'lstm': 1e-2,\n",
    "    'gpt2': 1e-4,\n",
    "    'roberta-base': 1e-5,\n",
    "    'bert-base-uncased': 1e-5\n",
    "}\n",
    "\n",
    "def get_average_scores(score_list):\n",
    "    if not score_list:\n",
    "        return (0.0, 0.0)\n",
    "\n",
    "    s1 = s2 = 0.0\n",
    "    n = 0\n",
    "    for a, b in score_list:\n",
    "        s1 += a\n",
    "        s2 += b\n",
    "        n += 1\n",
    "    return ((s1 / n * 100), (s2 / n * 100))\n",
    "\n",
    "def get_tuple_2f_fmt(tp):\n",
    "    f1, f2 = tp\n",
    "    return f\"{f1:.2f}/{f2:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f2125a-f9b6-4110-8255-99ce12aed5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 20\n",
    "\n",
    "# plms_funcs = {\n",
    "#     'PLMs': get_cbm_standard,\n",
    "#     'CBE-PLMs': get_cbm_joint\n",
    "# }\n",
    "\n",
    "# data_types = ['pure_cebab', 'aug_cebab']\n",
    "# model_names = ['bert-base-uncased', 'roberta-base', 'gpt2', 'lstm']\n",
    "# plms_results = {\n",
    "#     'data_type': [],\n",
    "#     'function': [],\n",
    "#     'model': [],\n",
    "#     'score': []\n",
    "# }\n",
    "\n",
    "# # functions\n",
    "# for f_name, f in plms_funcs.items():\n",
    "#     print(f\"Running {f_name}...\")\n",
    "#     for data_type in data_types:\n",
    "#         print(f\"\\tRunning {data_type}...\")\n",
    "#         for model_name in model_names:\n",
    "#             lr = lr_rate_dt.get(model_name)\n",
    "#             print(f\"\\t\\tRunning {model_name}... with learning rate: {lr}\")\n",
    "#             plms_results['data_type'].append(data_type)\n",
    "#             plms_results['function'].append(f_name)\n",
    "#             plms_results['model'].append(model_name)\n",
    "#             plms_results['score'].append(\n",
    "#                 f(\n",
    "#                     model_name=model_name,\n",
    "#                     num_epochs=num_epochs,\n",
    "#                     data_type=data_type,\n",
    "#                     max_len=512,\n",
    "#                     batch_size=8,\n",
    "#                     optimizer_lr=lr\n",
    "#                 )\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d92e9a6-31ba-4f15-ae78-d32b6821a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(plms_results)\n",
    "# df['score_avg'] = df.score.apply(get_average_scores)\n",
    "# df['score_fmted'] = df.score_avg.apply(get_tuple_2f_fmt)\n",
    "\n",
    "# df.to_csv(\"result.csv\", index=False)\n",
    "# df = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa1ce8d-44c2-4313-9294-3292312839c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pivot(index=['model'], columns=['data_type'], values='score_fmted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc7317-7823-40fb-b80a-2ff1411bb212",
   "metadata": {},
   "source": [
    "# Debug lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dabdab6-e6fb-4554-82ba-1b4c3e3e24e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './fasttext/cc.en.300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_cbm_joint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpure_cebab\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/CBM_NLP/run_cebab/cbm_joint.py:82\u001b[0m, in \u001b[0;36mget_cbm_joint\u001b[0;34m(mode, max_len, batch_size, model_name, num_epochs, data_type, optimizer_lr)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Initialize the classification model\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# model = GPT2Classifier(model)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 82\u001b[0m     fasttext_model \u001b[38;5;241m=\u001b[39m \u001b[43mFastText\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_fasttext_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./fasttext/cc.en.300.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m     model \u001b[38;5;241m=\u001b[39m BiLSTMWithDotAttention(\u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mvocab), \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m128\u001b[39m, fasttext_model)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gensim/utils.py:1521\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_func1\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1516\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1517\u001b[0m         fmt\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, reason\u001b[38;5;241m=\u001b[39mreason),\n\u001b[1;32m   1518\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1519\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1520\u001b[0m     )\n\u001b[0;32m-> 1521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gensim/models/fasttext.py:580\u001b[0m, in \u001b[0;36mFastText.load_fasttext_format\u001b[0;34m(cls, model_file, encoding)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse load_facebook_vectors (to use pretrained embeddings) or load_facebook_model \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(to continue training with the loaded full model, more RAM) instead\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_fasttext_format\u001b[39m(\u001b[38;5;28mcls\u001b[39m, model_file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    574\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deprecated.\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    Use :func:`gensim.models.fasttext.load_facebook_model` or\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    :func:`gensim.models.fasttext.load_facebook_vectors` instead.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_facebook_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gensim/models/fasttext.py:728\u001b[0m, in \u001b[0;36mload_facebook_model\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_facebook_model\u001b[39m(path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    667\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the model from Facebook's native fasttext `.bin` output file.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m \n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_fasttext_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gensim/models/fasttext.py:807\u001b[0m, in \u001b[0;36m_load_fasttext_format\u001b[0;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_fasttext_format\u001b[39m(model_file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, full_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the input-hidden weight matrix from Facebook's native fasttext `.bin` output files.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m \n\u001b[1;32m    806\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m    808\u001b[0m         m \u001b[38;5;241m=\u001b[39m gensim\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39m_fasttext_bin\u001b[38;5;241m.\u001b[39mload(fin, encoding\u001b[38;5;241m=\u001b[39mencoding, full_model\u001b[38;5;241m=\u001b[39mfull_model)\n\u001b[1;32m    810\u001b[0m     model \u001b[38;5;241m=\u001b[39m FastText(\n\u001b[1;32m    811\u001b[0m         vector_size\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mdim,\n\u001b[1;32m    812\u001b[0m         window\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mws,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m         max_n\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mmaxn,\n\u001b[1;32m    822\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/smart_open/smart_open_lib.py:170\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 170\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/smart_open/smart_open_lib.py:368\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    366\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fasttext/cc.en.300.bin'"
     ]
    }
   ],
   "source": [
    "get_cbm_joint(\n",
    "    model_name='lstm',\n",
    "    data_type='pure_cebab',\n",
    "    max_len=512,\n",
    "    batch_size=8,\n",
    "    optimizer_lr=1e-2,\n",
    "    num_epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7be673d-bca2-461f-8e4a-165b28304c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 146.54batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 130.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 18.589360430364614 Val Macro F1 = 39.15959068326081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 141.61batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Acc = 26.300059772863122 Val Macro F1 = 43.580593346239176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 142.04batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 127.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Acc = 37.53735803945009 Val Macro F1 = 54.19161836787206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 144.58batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 130.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Acc = 40.94441123729827 Val Macro F1 = 52.26537339514478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 145.70batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 131.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Acc = 40.28690974297669 Val Macro F1 = 56.047517537130545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 144.04batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 130.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Val Acc = 40.884638374178124 Val Macro F1 = 59.25138077608759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 140.73batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Val Acc = 42.61805140466228 Val Macro F1 = 59.46799875419598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 142.78batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Val Acc = 42.916915720263 Val Macro F1 = 61.686399601607334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 144.19batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 128.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Val Acc = 44.23191870890616 Val Macro F1 = 61.42256220763239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 138.56batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Val Acc = 45.068738792588164 Val Macro F1 = 64.3487884001755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 140.53batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 128.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Val Acc = 43.81350866706516 Val Macro F1 = 63.93413915363515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 139.95batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 128.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Val Acc = 39.98804542737597 Val Macro F1 = 62.12663398816731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 144.19batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Val Acc = 40.765092647937834 Val Macro F1 = 61.0872144000141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 141.94batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Val Acc = 46.92169754931261 Val Macro F1 = 65.38163148154557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 142.30batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 130.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Val Acc = 46.204423191870895 Val Macro F1 = 65.07033146760996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 142.48batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Val Acc = 44.7101016138673 Val Macro F1 = 64.51344244653792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 142.75batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 127.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Val Acc = 44.82964734010759 Val Macro F1 = 64.08943162131283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 140.38batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 128.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Val Acc = 47.75851763299462 Val Macro F1 = 66.07559612255646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 145.14batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 129.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val Acc = 45.2480573819486 Val Macro F1 = 63.77301948480293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 145.20batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 132.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Val Acc = 46.32396891811118 Val Macro F1 = 63.90545070477985\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:01<00:00, 127.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 45.519287833827896 Test Macro F1 = 64.13175706452957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.45519287833827893, 0.6413175706452957)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cbm_standard(\n",
    "    model_name='lstm',\n",
    "    data_type='aug_cebab',\n",
    "    max_len=512,\n",
    "    batch_size=8,\n",
    "    optimizer_lr=1e-2,\n",
    "    num_epochs=20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
