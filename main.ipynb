{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7267c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from run_cebab import get_cbm_standard, get_cbm_joint, get_cbm_LLM_mix_joint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955bbc2-f549-4292-95e5-bf2a6ed9e8bd",
   "metadata": {},
   "source": [
    "# Working Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fd5319-0aef-44e3-bd26-dee1c7dd49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can only run once when kernal start\n",
    "os.chdir('run_cebab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27131454-635f-4611-9bbf-48773292118c",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0b67e-846b-424f-97ea-8b25d106dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to call\n",
    "plms_funcs = {\n",
    "    'PLMs': get_cbm_standard,\n",
    "    'CBE-PLMs': get_cbm_joint,\n",
    "    'CBE-PLMs-CM': get_cbm_LLM_mix_joint\n",
    "}\n",
    "\n",
    "# D vs. D^\n",
    "data_types = ['pure_cebab', 'aug_cebab']\n",
    "\n",
    "# models\n",
    "model_names = ['bert-base-uncased', 'roberta-base', 'gpt2', 'lstm']\n",
    "\n",
    "# learning rate by model\n",
    "lr_rate_dt = {\n",
    "    'lstm': 1e-2,\n",
    "    'gpt2': 1e-4,\n",
    "    'roberta-base': 1e-5,\n",
    "    'bert-base-uncased': 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7108584a-4b6d-4e7b-a4dc-efaa36b4051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_scores(score_list):\n",
    "    if not score_list:\n",
    "        return (0.0, 0.0)\n",
    "\n",
    "    s1 = s2 = 0.0\n",
    "    n = 0\n",
    "    for a, b in score_list:\n",
    "        s1 += a\n",
    "        s2 += b\n",
    "        n += 1\n",
    "    return ((s1 / n * 100), (s2 / n * 100))\n",
    "\n",
    "def get_tuple_2f_fmt(tp):\n",
    "    f1, f2 = tp\n",
    "    return f\"{f1:.2f}/{f2:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f2125a-f9b6-4110-8255-99ce12aed5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PLMs...\n",
      "\tRunning pure_cebab...\n",
      "\t\tRunning bert-base-uncased... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.31batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 50.029886431560065 Val Macro F1 = 63.63764939723184\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:11<00:00, 18.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 50.68087625814092 Test Macro F1 = 63.87937748787647\n",
      "\t\tRunning roberta-base... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.38batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 64.07650926479378 Val Macro F1 = 72.35676723573592\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:11<00:00, 19.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 63.58792184724689 Test Macro F1 = 73.02175910556439\n",
      "\t\tRunning gpt2... with learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:30<00:00,  6.00batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 17.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 58.876270173341304 Val Macro F1 = 72.0512325062708\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:11<00:00, 17.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 60.50917702782712 Test Macro F1 = 72.9359530274976\n",
      "\t\tRunning lstm... with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 141.87batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 137.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 27.017334130304842 Val Macro F1 = 40.20214692628115\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:01<00:00, 137.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 27.29425695677916 Test Macro F1 = 40.23426598513936\n",
      "\tRunning aug_cebab...\n",
      "\t\tRunning bert-base-uncased... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.42batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 61.14763897190676 Val Macro F1 = 72.76223284139552\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:11<00:00, 18.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 61.36498516320474 Test Macro F1 = 72.87759048988632\n",
      "\t\tRunning roberta-base... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.38batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 67.90197250448297 Val Macro F1 = 78.26486852815819\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:11<00:00, 18.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 68.486646884273 Test Macro F1 = 78.85821107004375\n",
      "\t\tRunning gpt2... with learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:30<00:00,  6.02batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:12<00:00, 17.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 29.826658696951586 Val Macro F1 = 45.97102559543168\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:12<00:00, 17.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 29.554896142433236 Test Macro F1 = 45.70488734320543\n",
      "\t\tRunning lstm... with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 147.87batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 132.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc = 27.017334130304842 Val Macro F1 = 40.20214692628115\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:01<00:00, 127.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Acc = 27.299703264094955 Test Macro F1 = 40.234709433382285\n",
      "Running CBE-PLMs...\n",
      "\tRunning pure_cebab...\n",
      "\t\tRunning bert-base-uncased... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.40batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 44.02271368798566 Val concept Macro F1 = 51.60804964280153\n",
      "Epoch 1: Val Acc = 62.94082486551106 Val Macro F1 = 73.5520832695864\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:11<00:00, 18.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 43.17643576080521 Test concept Macro F1 = 51.36825859929996\n",
      "Epoch 1: Test Acc = 65.66015393724098 Test Macro F1 = 75.0660301708592\n",
      "\t\tRunning roberta-base... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.36batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 57.38194859533772 Val concept Macro F1 = 61.35688096540086\n",
      "Epoch 1: Val Acc = 66.52719665271967 Val Macro F1 = 75.84625646384158\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:11<00:00, 19.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 58.229721728833624 Test concept Macro F1 = 61.88925853072496\n",
      "Epoch 1: Test Acc = 66.0153937240971 Test Macro F1 = 75.91776623287603\n",
      "\t\tRunning gpt2... with learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:30<00:00,  6.01batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:12<00:00, 17.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 59.98206814106396 Val concept Macro F1 = 62.824589819880174\n",
      "Epoch 1: Val Acc = 52.65989240884639 Val Macro F1 = 67.05098219962775\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:12<00:00, 17.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 60.52397868561279 Test concept Macro F1 = 62.92699870271543\n",
      "Epoch 1: Test Acc = 53.522794552989936 Test Macro F1 = 67.36727592522193\n",
      "\t\tRunning lstm... with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 134.27batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 131.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 55.24506873879259 Val concept Macro F1 = 54.407725262073455\n",
      "Epoch 1: Val Acc = 21.219366407650927 Val Macro F1 = 41.9981468720971\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 212/212 [00:01<00:00, 127.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 56.867969212551806 Test concept Macro F1 = 54.83383673131463\n",
      "Epoch 1: Test Acc = 20.663114268798104 Test Macro F1 = 41.660813540387274\n",
      "\tRunning aug_cebab...\n",
      "\t\tRunning bert-base-uncased... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.38batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 55.7501494321578 Val concept Macro F1 = 51.650724725735756\n",
      "Epoch 1: Val Acc = 64.55469216975493 Val Macro F1 = 76.14642920762552\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:11<00:00, 18.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 55.98219584569733 Test concept Macro F1 = 51.63683500963497\n",
      "Epoch 1: Test Acc = 63.026706231454014 Test Macro F1 = 75.65698610303576\n",
      "\t\tRunning roberta-base... with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 183/183 [00:28<00:00,  6.35batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:11<00:00, 18.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 62.52839210998208 Val concept Macro F1 = 61.41055088252284\n",
      "Epoch 1: Val Acc = 69.63538553496711 Val Macro F1 = 79.37846917217557\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:11<00:00, 18.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 63.85756676557863 Test concept Macro F1 = 61.98637611692154\n",
      "Epoch 1: Test Acc = 67.00296735905044 Test Macro F1 = 78.66227180841682\n",
      "\t\tRunning gpt2... with learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:30<00:00,  5.99batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:12<00:00, 17.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 50.41841004184101 Val concept Macro F1 = 51.25309623279464\n",
      "Epoch 1: Val Acc = 59.83263598326359 Val Macro F1 = 73.25395248503227\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:12<00:00, 17.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 51.471810089020764 Test concept Macro F1 = 51.48673718832424\n",
      "Epoch 1: Test Acc = 59.82195845697329 Test Macro F1 = 73.53339767494136\n",
      "\t\tRunning lstm... with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 183/183 [00:01<00:00, 119.26batch/s]\n",
      "Val: 100%|██████████| 210/210 [00:01<00:00, 125.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val concept Acc = 75.54692169754932 Val concept Macro F1 = 57.60844696101505\n",
      "Epoch 1: Val Acc = 27.017334130304842 Val Macro F1 = 40.20214692628115\n",
      "Test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 211/211 [00:01<00:00, 124.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test concept Acc = 75.83382789317508 Test concept Macro F1 = 57.835447050058974\n",
      "Epoch 1: Test Acc = 27.299703264094955 Test Macro F1 = 40.234709433382285\n",
      "Running CBE-PLMs-CM...\n",
      "\tRunning pure_cebab...\n",
      "\t\tRunning bert-base-uncased... with learning rate: 1e-05\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'train_split' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m plms_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(f_name)\n\u001b[1;32m     28\u001b[0m plms_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_name)\n\u001b[1;32m     29\u001b[0m plms_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m~/repos/CBM_NLP/run_cebab/cbm_mix_joint.py:252\u001b[0m, in \u001b[0;36mget_cbm_mix_joint\u001b[0;34m(mode, max_len, batch_size, model_name, num_epochs, data_type, optimizer_lr)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m MyDataset(\u001b[43mtrain_split\u001b[49m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# val_dataset = MyDataset('validation')\u001b[39;00m\n\u001b[1;32m    254\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m MyDataset(test_split)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'train_split' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "\n",
    "results = {\n",
    "    'data_type': [],\n",
    "    'function': [],\n",
    "    'model': [],\n",
    "    'score': []\n",
    "}\n",
    "\n",
    "# functions\n",
    "for f_name, f in plms_funcs.items():\n",
    "    print(f\"Running {f_name}...\")\n",
    "    for data_type in data_types:\n",
    "        print(f\"\\tRunning {data_type}...\")\n",
    "        for model_name in model_names:\n",
    "            lr = lr_rate_dt.get(model_name)\n",
    "            print(f\"\\t\\tRunning {model_name}... with learning rate: {lr}\")\n",
    "            results['data_type'].append(data_type)\n",
    "            results['function'].append(f_name)\n",
    "            results['model'].append(model_name)\n",
    "            results['score'].append(\n",
    "                f(\n",
    "                    model_name=model_name,\n",
    "                    num_epochs=num_epochs,\n",
    "                    data_type=data_type,\n",
    "                    max_len=512,\n",
    "                    batch_size=8,\n",
    "                    optimizer_lr=lr\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d92e9a6-31ba-4f15-ae78-d32b6821a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results)\n",
    "df['score_avg'] = df.score.apply(get_average_scores)\n",
    "df['score_fmted'] = df.score_avg.apply(get_tuple_2f_fmt)\n",
    "\n",
    "df.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa1ce8d-44c2-4313-9294-3292312839c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index=['model'], columns=['data_type'], values='score_fmted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
